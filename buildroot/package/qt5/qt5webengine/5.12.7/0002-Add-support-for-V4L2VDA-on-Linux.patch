From 44984417ec9a703308d47046111496fc8f4d6f06 Mon Sep 17 00:00:00 2001
From: Maksim Sisov <msisov@igalia.com>
Date: Wed, 31 Jul 2019 09:56:24 +0300
Subject: [PATCH 2/8] Add support for V4L2VDA on Linux

This patch enables hardware assisted video decoding via the
Chromium V4L2VDA. Including changes when Linux is used. In
order to use this, use_linux_v4l2_only flag should be set
to true.

Signed-off-by: Ryo Kodama <ryo.kodama.vz@renesas.com>

fixup! avoid building not declared formats

"FRAME", "_SLICE",  "V4L2_PIX_FMT_VP9" are not defined in mainline
 Linux headers. This patch avoids building these formats.

Signed-off-by: Ryo Kodama <ryo.kodama.vz@renesas.com>

fixup! add V4L2_PIX_FMT_VP9 support back again as it is now
included in mainline Linux kernel. This allows VP9 codec
to work with upstream kernel and v4l2 vda. Tested on db820c
with Venus v4l2 driver.

Signed-off-by: Peter Griffin <peter.griffin@linaro.org>
Signed-off-by: Stanimir Varbanov <stanimir.varbanov@linaro.org>
Signed-off-by: Jeffy Chen <jeffy.chen@rock-chips.com>
---
 src/3rdparty/chromium/media/gpu/BUILD.gn      | 15 +++++++++-----
 src/3rdparty/chromium/media/gpu/args.gni      |  4 ++++
 .../gpu_jpeg_decode_accelerator_factory.cc    |  3 ++-
 .../gpu_video_decode_accelerator_factory.cc   |  8 ++++++++
 .../gpu_video_decode_accelerator_factory.h    |  2 ++
 .../media/gpu/v4l2/generic_v4l2_device.cc     |  6 +++++-
 .../chromium/media/gpu/v4l2/v4l2_device.cc    | 20 +++++++++++++++++++
 .../chromium/media/gpu/v4l2/v4l2_device.h     |  4 ++++
 8 files changed, 55 insertions(+), 7 deletions(-)

diff --git a/src/3rdparty/chromium/media/gpu/BUILD.gn b/src/3rdparty/chromium/media/gpu/BUILD.gn
index c8c7a19cc..f28d2d278 100644
--- a/src/3rdparty/chromium/media/gpu/BUILD.gn
+++ b/src/3rdparty/chromium/media/gpu/BUILD.gn
@@ -16,6 +16,7 @@ buildflag_header("buildflags") {
     "USE_VAAPI=$use_vaapi",
     "USE_V4L2_CODEC=$use_v4l2_codec",
     "USE_LIBV4L2=$use_v4lplugin",
+    "USE_LINUX_V4L2=$use_linux_v4l2_only",
   ]
 }
 
@@ -23,7 +24,7 @@ if (is_mac) {
   import("//build/config/mac/mac_sdk.gni")
 }
 
-if (is_chromeos && use_v4lplugin) {
+if (use_v4lplugin) {
   action("libv4l2_generate_stubs") {
     extra_header = "v4l2/v4l2_stub_header.fragment"
 
@@ -233,15 +234,19 @@ component("gpu") {
       "v4l2/v4l2_device.h",
       "v4l2/v4l2_image_processor.cc",
       "v4l2/v4l2_image_processor.h",
-      "v4l2/v4l2_jpeg_decode_accelerator.cc",
-      "v4l2/v4l2_jpeg_decode_accelerator.h",
-      "v4l2/v4l2_slice_video_decode_accelerator.cc",
-      "v4l2/v4l2_slice_video_decode_accelerator.h",
       "v4l2/v4l2_video_decode_accelerator.cc",
       "v4l2/v4l2_video_decode_accelerator.h",
       "v4l2/v4l2_video_encode_accelerator.cc",
       "v4l2/v4l2_video_encode_accelerator.h",
     ]
+    if (!use_linux_v4l2_only) {
+      sources += [
+        "v4l2_jpeg_decode_accelerator.cc",
+        "v4l2_jpeg_decode_accelerator.h",
+        "v4l2_slice_video_decode_accelerator.cc",
+        "v4l2_slice_video_decode_accelerator.h",
+      ]
+    }
     libs = [
       "EGL",
       "GLESv2",
diff --git a/src/3rdparty/chromium/media/gpu/args.gni b/src/3rdparty/chromium/media/gpu/args.gni
index df4b0f980..ac740ffee 100644
--- a/src/3rdparty/chromium/media/gpu/args.gni
+++ b/src/3rdparty/chromium/media/gpu/args.gni
@@ -10,6 +10,10 @@ declare_args() {
   # platforms which have v4l2 hardware encoder / decoder.
   use_v4l2_codec = false
 
+  # Indicates that only definitions available in the mainline linux kernel
+  # will be used.
+  use_linux_v4l2_only = false
+
   # Indicates if VA-API-based hardware acceleration is to be used. This
   # is typically the case on x86-based ChromeOS devices.
   use_vaapi = false
diff --git a/src/3rdparty/chromium/media/gpu/gpu_jpeg_decode_accelerator_factory.cc b/src/3rdparty/chromium/media/gpu/gpu_jpeg_decode_accelerator_factory.cc
index c0dfb52cc..1148e752f 100644
--- a/src/3rdparty/chromium/media/gpu/gpu_jpeg_decode_accelerator_factory.cc
+++ b/src/3rdparty/chromium/media/gpu/gpu_jpeg_decode_accelerator_factory.cc
@@ -13,7 +13,8 @@
 #include "media/gpu/buildflags.h"
 #include "media/gpu/fake_jpeg_decode_accelerator.h"
 
-#if BUILDFLAG(USE_V4L2_CODEC) && defined(ARCH_CPU_ARM_FAMILY)
+#if BUILDFLAG(USE_V4L2_CODEC) && defined(ARCH_CPU_ARM_FAMILY) && \
+    !BUILDFLAG(USE_LINUX_V4L2)
 #define USE_V4L2_JDA
 #endif
 
diff --git a/src/3rdparty/chromium/media/gpu/gpu_video_decode_accelerator_factory.cc b/src/3rdparty/chromium/media/gpu/gpu_video_decode_accelerator_factory.cc
index 85d2edb50..1dff7164f 100644
--- a/src/3rdparty/chromium/media/gpu/gpu_video_decode_accelerator_factory.cc
+++ b/src/3rdparty/chromium/media/gpu/gpu_video_decode_accelerator_factory.cc
@@ -24,7 +24,9 @@
 #endif
 #if BUILDFLAG(USE_V4L2_CODEC)
 #include "media/gpu/v4l2/v4l2_device.h"
+#if !BUILDFLAG(USE_LINUX_V4L2)
 #include "media/gpu/v4l2/v4l2_slice_video_decode_accelerator.h"
+#endif
 #include "media/gpu/v4l2/v4l2_video_decode_accelerator.h"
 #include "ui/gl/gl_surface_egl.h"
 #endif
@@ -98,10 +100,12 @@ GpuVideoDecodeAcceleratorFactory::GetDecoderCapabilities(
   vda_profiles = V4L2VideoDecodeAccelerator::GetSupportedProfiles();
   GpuVideoAcceleratorUtil::InsertUniqueDecodeProfiles(
       vda_profiles, &capabilities.supported_profiles);
+#if !BUILDFLAG(USE_LINUX_V4L2)
   vda_profiles = V4L2SliceVideoDecodeAccelerator::GetSupportedProfiles();
   GpuVideoAcceleratorUtil::InsertUniqueDecodeProfiles(
       vda_profiles, &capabilities.supported_profiles);
 #endif
+#endif
 #if BUILDFLAG(USE_VAAPI)
   vda_profiles = VaapiVideoDecodeAccelerator::GetSupportedProfiles();
   GpuVideoAcceleratorUtil::InsertUniqueDecodeProfiles(
@@ -144,8 +148,10 @@ GpuVideoDecodeAcceleratorFactory::CreateVDA(
 #endif
 #if BUILDFLAG(USE_V4L2_CODEC)
     &GpuVideoDecodeAcceleratorFactory::CreateV4L2VDA,
+#if !BUILDFLAG(USE_LINUX_V4L2)
     &GpuVideoDecodeAcceleratorFactory::CreateV4L2SVDA,
 #endif
+#endif
 #if BUILDFLAG(USE_VAAPI)
     &GpuVideoDecodeAcceleratorFactory::CreateVaapiVDA,
 #endif
@@ -199,6 +205,7 @@ GpuVideoDecodeAcceleratorFactory::CreateV4L2VDA(
   return decoder;
 }
 
+#if !BUILDFLAG(USE_LINUX_V4L2)
 std::unique_ptr<VideoDecodeAccelerator>
 GpuVideoDecodeAcceleratorFactory::CreateV4L2SVDA(
     const gpu::GpuDriverBugWorkarounds& workarounds,
@@ -214,6 +221,7 @@ GpuVideoDecodeAcceleratorFactory::CreateV4L2SVDA(
   return decoder;
 }
 #endif
+#endif
 
 #if BUILDFLAG(USE_VAAPI)
 std::unique_ptr<VideoDecodeAccelerator>
diff --git a/src/3rdparty/chromium/media/gpu/gpu_video_decode_accelerator_factory.h b/src/3rdparty/chromium/media/gpu/gpu_video_decode_accelerator_factory.h
index 3c94bdcdc..e9127bf55 100644
--- a/src/3rdparty/chromium/media/gpu/gpu_video_decode_accelerator_factory.h
+++ b/src/3rdparty/chromium/media/gpu/gpu_video_decode_accelerator_factory.h
@@ -108,11 +108,13 @@ class MEDIA_GPU_EXPORT GpuVideoDecodeAcceleratorFactory {
       const gpu::GpuDriverBugWorkarounds& workarounds,
       const gpu::GpuPreferences& gpu_preferences,
       MediaLog* media_log) const;
+#if !BUILDFLAG(USE_LINUX_V4L2)
   std::unique_ptr<VideoDecodeAccelerator> CreateV4L2SVDA(
       const gpu::GpuDriverBugWorkarounds& workarounds,
       const gpu::GpuPreferences& gpu_preferences,
       MediaLog* media_log) const;
 #endif
+#endif
 #if BUILDFLAG(USE_VAAPI)
   std::unique_ptr<VideoDecodeAccelerator> CreateVaapiVDA(
       const gpu::GpuDriverBugWorkarounds& workarounds,
diff --git a/src/3rdparty/chromium/media/gpu/v4l2/generic_v4l2_device.cc b/src/3rdparty/chromium/media/gpu/v4l2/generic_v4l2_device.cc
index 45220eb04..a230efc75 100644
--- a/src/3rdparty/chromium/media/gpu/v4l2/generic_v4l2_device.cc
+++ b/src/3rdparty/chromium/media/gpu/v4l2/generic_v4l2_device.cc
@@ -202,7 +202,7 @@ std::vector<base::ScopedFD> GenericV4L2Device::GetDmabufsForV4L2Buffer(
 bool GenericV4L2Device::CanCreateEGLImageFrom(uint32_t v4l2_pixfmt) {
   static uint32_t kEGLImageDrmFmtsSupported[] = {
     DRM_FORMAT_ARGB8888,
-#if defined(ARCH_CPU_ARMEL)
+#if defined(ARCH_CPU_ARM_FAMILY)
     DRM_FORMAT_NV12,
     DRM_FORMAT_YVU420,
 #endif
@@ -474,7 +474,11 @@ bool GenericV4L2Device::OpenDevicePath(const std::string& path, Type type) {
     return false;
 
 #if BUILDFLAG(USE_LIBV4L2)
+#if BUILDFLAG(USE_LINUX_V4L2)
+  if (
+#else
   if (type == Type::kEncoder &&
+#endif
       HANDLE_EINTR(v4l2_fd_open(device_fd_.get(), V4L2_DISABLE_CONVERSION)) !=
           -1) {
     VLOGF(2) << "Using libv4l2 for " << path;
diff --git a/src/3rdparty/chromium/media/gpu/v4l2/v4l2_device.cc b/src/3rdparty/chromium/media/gpu/v4l2/v4l2_device.cc
index 30dc1bd92..30f03abb3 100644
--- a/src/3rdparty/chromium/media/gpu/v4l2/v4l2_device.cc
+++ b/src/3rdparty/chromium/media/gpu/v4l2/v4l2_device.cc
@@ -96,20 +96,32 @@ uint32_t V4L2Device::VideoPixelFormatToV4L2PixFmt(VideoPixelFormat format) {
 uint32_t V4L2Device::VideoCodecProfileToV4L2PixFmt(VideoCodecProfile profile,
                                                    bool slice_based) {
   if (profile >= H264PROFILE_MIN && profile <= H264PROFILE_MAX) {
+#if !BUILDFLAG(USE_LINUX_V4L2)
     if (slice_based)
       return V4L2_PIX_FMT_H264_SLICE;
     else
       return V4L2_PIX_FMT_H264;
+#else
+    return V4L2_PIX_FMT_H264;
+#endif
   } else if (profile >= VP8PROFILE_MIN && profile <= VP8PROFILE_MAX) {
+#if !BUILDFLAG(USE_LINUX_V4L2)
     if (slice_based)
       return V4L2_PIX_FMT_VP8_FRAME;
     else
       return V4L2_PIX_FMT_VP8;
+#else
+    return V4L2_PIX_FMT_VP8;
+#endif
   } else if (profile >= VP9PROFILE_MIN && profile <= VP9PROFILE_MAX) {
+#if !BUILDFLAG(USE_LINUX_V4L2)
     if (slice_based)
       return V4L2_PIX_FMT_VP9_FRAME;
     else
       return V4L2_PIX_FMT_VP9;
+#else
+    return V4L2_PIX_FMT_VP9;
+#endif
   } else {
     LOG(FATAL) << "Add more cases as needed";
     return 0;
@@ -125,7 +137,9 @@ std::vector<VideoCodecProfile> V4L2Device::V4L2PixFmtToVideoCodecProfiles(
 
   switch (pix_fmt) {
     case V4L2_PIX_FMT_H264:
+#if !BUILDFLAG(USE_LINUX_V4L2)
     case V4L2_PIX_FMT_H264_SLICE:
+#endif
       if (is_encoder) {
         // TODO(posciak): need to query the device for supported H.264 profiles,
         // for now choose Main as a sensible default.
@@ -138,13 +152,17 @@ std::vector<VideoCodecProfile> V4L2Device::V4L2PixFmtToVideoCodecProfiles(
       break;
 
     case V4L2_PIX_FMT_VP8:
+#if !BUILDFLAG(USE_LINUX_V4L2)
     case V4L2_PIX_FMT_VP8_FRAME:
+#endif
       min_profile = VP8PROFILE_MIN;
       max_profile = VP8PROFILE_MAX;
       break;
 
     case V4L2_PIX_FMT_VP9:
+#if !BUILDFLAG(USE_LINUX_V4L2)
     case V4L2_PIX_FMT_VP9_FRAME:
+#endif
       // TODO(posciak): https://crbug.com/819930 Query supported profiles.
       // Currently no devices support Profiles > 0 https://crbug.com/796297.
       min_profile = VP9PROFILE_PROFILE0;
@@ -179,8 +197,10 @@ uint32_t V4L2Device::V4L2PixFmtToDrmFormat(uint32_t format) {
     case V4L2_PIX_FMT_RGB32:
       return DRM_FORMAT_ARGB8888;
 
+#if !BUILDFLAG(USE_LINUX_V4L2)
     case V4L2_PIX_FMT_MT21:
       return DRM_FORMAT_MT21;
+#endif
 
     default:
       DVLOGF(1) << "Unrecognized format " << std::hex << "0x" << format;
diff --git a/src/3rdparty/chromium/media/gpu/v4l2/v4l2_device.h b/src/3rdparty/chromium/media/gpu/v4l2/v4l2_device.h
index 44cc3cc51..64268a2e0 100644
--- a/src/3rdparty/chromium/media/gpu/v4l2/v4l2_device.h
+++ b/src/3rdparty/chromium/media/gpu/v4l2/v4l2_device.h
@@ -31,6 +31,10 @@
 #define V4L2_BUF_FLAG_LAST 0x00100000
 #endif
 
+#ifndef V4L2_PIX_FMT_VP9
+#define V4L2_PIX_FMT_VP9 v4l2_fourcc('V', 'P', '9', '0')
+#endif
+
 namespace media {
 
 class MEDIA_GPU_EXPORT V4L2Device
-- 
2.20.1

